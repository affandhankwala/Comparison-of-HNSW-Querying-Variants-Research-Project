Down with the hierarchy: FlatNav better than HNSW in higher dimensions
FINGER: better estimation metric by overlooking intermediate calculations
Omni-KNN: More efficient with improve classification and robustness
Dual-branch HNSW: Traversal in multiple dimensions
HENN: quicker query time

Construction: Dynamic HNSW -> improve dimensionality by customizing M and ef per node
Querying: FINGER  -> Speed up querying time by storing many calculations and using simplified distance metric involving risiduals 
Add multi-dimensional traversal -> Remove local optima issue. LID can be used to determine density of data points around query

Finger vs Distance Adaptive Beam Search 
HNSW++ vs DHNSW
All versus HNSW, ANN, and FlatNav

Compare the performance in speed, memory usage, and recall with each combination of FINGER or Distance Adaptive Beam Search querying algorithms with HNSW++ or DHNSW construction methods and compare them to the performance metrics of traditional HNSW and ANN and the proposed efficient FlatNav on a variety of datasets and dimensions. 